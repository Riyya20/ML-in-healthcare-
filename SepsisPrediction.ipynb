{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6574f6b-198a-4322-9178-1ce7b2ca0c63",
   "metadata": {},
   "source": [
    "Prediction of Sepsis from clinical data using Random forest and Gradient boosting.\n",
    "This project focuses on developing a machine-learning model to predict sepsis using patient clinical data. Sepsis is a life-threatening condition that arises when the body's response to infection causes injury to its own tissues and organs. Early detection is crucial for effective treatment. The dataset was taken from Kaggle (\"Prediction of Sepsis\" dataset) and contains clinical variables like heart rate (HR), oxygen saturation (O2Sat), temperature (Temp), blood pressure (SBP, MAP, DBP), and more. \n",
    "The missing values were handled as follows :\n",
    "1. Mean imputation for numerical features.\n",
    "2. Mode imputation for categorical features.\n",
    "3. Median imputation for numerical features prone to outliers.\n",
    "Split was 80% training 20% testing.\n",
    "Two machine learning models were used :\n",
    "1. Random forest Classifier :\n",
    "Accuracy: 98.37%\n",
    "2. Gradient Boosting Classifier\n",
    "Accuracy:¬†98.22%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e129b88-31f3-4048-813d-53f13b842bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\anaconda\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94ea3e30-eeed-4122-93b6-ef2ea496e025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in d:\\anaconda\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00224e38-7b08-485e-b252-ef24cf019c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.10 in d:\\anaconda\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in d:\\anaconda\\lib\\site-packages (from kaggle) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil in d:\\anaconda\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from kaggle) (4.66.5)\n",
      "Requirement already satisfied: python-slugify in d:\\anaconda\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in d:\\anaconda\\lib\\site-packages (from kaggle) (2.2.3)\n",
      "Requirement already satisfied: bleach in d:\\anaconda\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\lib\\site-packages (from bleach->kaggle) (24.1)\n",
      "Requirement already satisfied: webencodings in d:\\anaconda\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in d:\\anaconda\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->kaggle) (3.7)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105797 sha256=8a939494d9c923423452609258d204998e76435d3e9e60e98b34a3c5c37a1ba8\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\46\\d2\\26\\84d0a1acdb9c6baccf7d28cf06962ec80529fe1ad938489983\n",
      "Successfully built kaggle\n",
      "Installing collected packages: kaggle\n",
      "Successfully installed kaggle-1.6.17\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29d93bca-4ed0-4bb7-a828-35ea789a5316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Admin\\\\.kaggle\\\\kaggle.json'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the correct path for Windows\n",
    "kaggle_path = os.path.join(os.path.expanduser(\"~\"), \".kaggle\")\n",
    "os.makedirs(kaggle_path, exist_ok=True)\n",
    "\n",
    "# Move the kaggle.json file (adjust the source path if needed)\n",
    "shutil.move(r\"C:\\Users\\Admin\\Downloads\\kaggle.json\", os.path.join(kaggle_path, \"kaggle.json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d0d73a6-db34-4bdb-b765-18f56bf99c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                                           title                                              size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
      "------------------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
      "anandshaw2001/netflix-movies-and-tv-shows                     Netflix Movies and TV Shows                         1MB  2025-01-03 10:33:01          12474        323  1.0              \n",
      "himelsarder/road-accident-survival-dataset                    Road Accident Survival Dataset                      1KB  2025-01-18 06:00:32           1681         23  1.0              \n",
      "asinow/airplane-price-dataset                                 Airplane Price Dataset                            238KB  2025-01-28 18:36:41           1793         28  0.9411765        \n",
      "asinow/car-price-dataset                                      Car Price Dataset                                 135KB  2025-01-26 19:53:28           2132         34  1.0              \n",
      "ankushpanday1/alzheimers-prediction-dataset-global            Alzheimer‚Äôs Prediction Dataset (Global)             1MB  2025-01-30 14:38:39            826         26  1.0              \n",
      "ankushpanday1/global-road-accidents-dataset                   Global Road Accidents Dataset                      12MB  2025-01-25 04:22:29           2055         52  1.0              \n",
      "samithsachidanandan/gdp-by-country-1960-2023                  GDP By Country 1960 - 2023 üåç                       80KB  2025-01-24 16:26:01            861         25  1.0              \n",
      "shriyashjagtap/heart-attack-risk-assessment-dataset           Heart Attack Risk Assessment Dataset               49KB  2025-01-31 15:41:10            705         27  1.0              \n",
      "ashaychoudhary/dataset-mba-decision-after-bachelors           Dataset: MBA Decision After Bachelor's            284KB  2025-01-17 04:41:28           2788         64  1.0              \n",
      "oktayrdeki/traffic-accidents                                  Traffic Accidents                                   5MB  2025-01-20 10:33:44           2795         58  1.0              \n",
      "ashaychoudhary/anxiety-attack-factors-symptoms-and-severity   Anxiety Attack : Factors, Symptoms, and Severity  244KB  2025-01-19 11:56:21           2887         54  1.0              \n",
      "ruchikakumbhar/placement-prediction-dataset                   Placement Prediction Dataset                      100KB  2025-01-20 06:48:57           1510         29  1.0              \n",
      "ankushpanday1/brain-tumor-prediction-dataset                  Brain Tumor Prediction Dataset                      5MB  2025-01-29 18:10:09            541         27  1.0              \n",
      "ankushpanday1/usa-statewise-daily-temperature-december-2024   USA Statewise Daily Temperature: December 2024      6KB  2025-01-28 05:35:09            803         24  1.0              \n",
      "michaelmatta0/movies-ultimate-metrics-features-and-metadata   Movies Ultimate Metrics, Features and Statistics    3MB  2025-01-30 09:29:26            532         22  1.0              \n",
      "yxshee/electric-vehicle-dataset                               Electric Vehicle Dataset                            7MB  2025-01-21 17:12:50            884         24  1.0              \n",
      "ruchikakumbhar/obesity-prediction                             Obesity Prediction Dataset                         58KB  2025-01-14 05:31:18           3581         53  1.0              \n",
      "ankushpanday1/pancreatic-cancer-prediction-dataset            Pancreatic Cancer Prediction Dataset              599KB  2025-01-31 13:24:14            390         23  1.0              \n",
      "ahmedmohamed2003/cafe-sales-dirty-data-for-cleaning-training  Cafe Sales - Dirty Data for Cleaning Training     111KB  2025-01-17 19:49:39           2866         58  1.0              \n",
      "ashaychoudhary/tourist-travel-modes-in-europe-dataset         Tourist Travel Modes in Europe Dataset             12KB  2025-01-21 04:45:33            831         25  1.0              \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "890f2dec-b8cb-4d37-95cc-5f8d9aa17fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in d:\\anaconda\\lib\\site-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in d:\\anaconda\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in d:\\anaconda\\lib\\site-packages (from kaggle) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil in d:\\anaconda\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from kaggle) (4.66.5)\n",
      "Requirement already satisfied: python-slugify in d:\\anaconda\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in d:\\anaconda\\lib\\site-packages (from kaggle) (2.2.3)\n",
      "Requirement already satisfied: bleach in d:\\anaconda\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\lib\\site-packages (from bleach->kaggle) (24.1)\n",
      "Requirement already satisfied: webencodings in d:\\anaconda\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in d:\\anaconda\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->kaggle) (3.7)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66820c9a-7e94-45e5-9962-d44313836252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/salikhussaini49/prediction-of-sepsis\n",
      "License(s): CC-BY-NC-SA-4.0\n",
      "Downloading prediction-of-sepsis.zip to C:\\Users\\Admin\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/74.7M [00:00<?, ?B/s]\n",
      "  1%|‚ñè         | 1.00M/74.7M [00:01<01:46, 725kB/s]\n",
      "  3%|‚ñé         | 2.00M/74.7M [00:01<00:52, 1.46MB/s]\n",
      "  4%|‚ñç         | 3.00M/74.7M [00:01<00:31, 2.35MB/s]\n",
      "  7%|‚ñã         | 5.00M/74.7M [00:01<00:16, 4.45MB/s]\n",
      "  8%|‚ñä         | 6.00M/74.7M [00:02<00:13, 5.15MB/s]\n",
      "  9%|‚ñâ         | 7.00M/74.7M [00:02<00:13, 5.42MB/s]\n",
      " 11%|‚ñà         | 8.00M/74.7M [00:02<00:13, 5.29MB/s]\n",
      " 12%|‚ñà‚ñè        | 9.00M/74.7M [00:02<00:13, 5.18MB/s]\n",
      " 13%|‚ñà‚ñé        | 10.0M/74.7M [00:02<00:14, 4.64MB/s]\n",
      " 15%|‚ñà‚ñç        | 11.0M/74.7M [00:03<00:13, 5.00MB/s]\n",
      " 16%|‚ñà‚ñå        | 12.0M/74.7M [00:03<00:13, 5.03MB/s]\n",
      " 17%|‚ñà‚ñã        | 13.0M/74.7M [00:03<00:12, 5.00MB/s]\n",
      " 19%|‚ñà‚ñâ        | 14.0M/74.7M [00:03<00:13, 4.77MB/s]\n",
      " 20%|‚ñà‚ñà        | 15.0M/74.7M [00:03<00:13, 4.79MB/s]\n",
      " 21%|‚ñà‚ñà‚ñè       | 16.0M/74.7M [00:04<00:15, 4.09MB/s]\n",
      " 23%|‚ñà‚ñà‚ñé       | 17.0M/74.7M [00:04<00:15, 3.94MB/s]\n",
      " 24%|‚ñà‚ñà‚ñç       | 18.0M/74.7M [00:04<00:14, 4.21MB/s]\n",
      " 25%|‚ñà‚ñà‚ñå       | 19.0M/74.7M [00:05<00:13, 4.41MB/s]\n",
      " 27%|‚ñà‚ñà‚ñã       | 20.0M/74.7M [00:05<00:13, 4.34MB/s]\n",
      " 28%|‚ñà‚ñà‚ñä       | 21.0M/74.7M [00:05<00:13, 4.16MB/s]\n",
      " 29%|‚ñà‚ñà‚ñâ       | 22.0M/74.7M [00:05<00:16, 3.39MB/s]\n",
      " 31%|‚ñà‚ñà‚ñà       | 23.0M/74.7M [00:06<00:21, 2.54MB/s]\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 24.0M/74.7M [00:07<00:26, 2.02MB/s]\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 25.0M/74.7M [00:08<00:30, 1.70MB/s]\n",
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 26.0M/74.7M [00:08<00:26, 1.91MB/s]\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 27.0M/74.7M [00:08<00:21, 2.32MB/s]\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 28.0M/74.7M [00:09<00:16, 2.95MB/s]\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 30.0M/74.7M [00:09<00:10, 4.56MB/s]\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 32.0M/74.7M [00:09<00:08, 5.11MB/s]\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 33.0M/74.7M [00:09<00:07, 5.63MB/s]\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 34.0M/74.7M [00:09<00:08, 4.87MB/s]\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 35.0M/74.7M [00:10<00:09, 4.43MB/s]\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 37.0M/74.7M [00:10<00:07, 5.32MB/s]\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 38.0M/74.7M [00:10<00:07, 5.20MB/s]\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 39.0M/74.7M [00:10<00:06, 5.38MB/s]\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 40.0M/74.7M [00:11<00:07, 4.89MB/s]\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 41.0M/74.7M [00:11<00:06, 5.12MB/s]\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 42.0M/74.7M [00:11<00:06, 5.01MB/s]\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 43.0M/74.7M [00:11<00:06, 4.92MB/s]\n",
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 44.0M/74.7M [00:12<00:06, 4.81MB/s]\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 45.0M/74.7M [00:12<00:06, 4.53MB/s]\n",
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 46.0M/74.7M [00:12<00:06, 4.60MB/s]\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 47.0M/74.7M [00:12<00:06, 4.56MB/s]\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 48.0M/74.7M [00:12<00:05, 4.78MB/s]\n",
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 49.0M/74.7M [00:13<00:05, 5.00MB/s]\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 50.0M/74.7M [00:13<00:04, 5.20MB/s]\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 51.0M/74.7M [00:13<00:04, 5.36MB/s]\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 52.0M/74.7M [00:13<00:04, 5.23MB/s]\n",
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 53.0M/74.7M [00:13<00:04, 4.83MB/s]\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 54.0M/74.7M [00:14<00:04, 4.89MB/s]\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 55.0M/74.7M [00:14<00:04, 4.91MB/s]\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 56.0M/74.7M [00:14<00:04, 4.60MB/s]\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 57.0M/74.7M [00:14<00:03, 4.77MB/s]\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 58.0M/74.7M [00:15<00:03, 4.63MB/s]\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 59.0M/74.7M [00:15<00:03, 4.70MB/s]\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 60.0M/74.7M [00:15<00:03, 4.78MB/s]\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 61.0M/74.7M [00:15<00:02, 4.88MB/s]\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 62.0M/74.7M [00:15<00:02, 5.16MB/s]\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 63.0M/74.7M [00:16<00:02, 4.95MB/s]\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 64.0M/74.7M [00:16<00:02, 5.31MB/s]\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 65.0M/74.7M [00:16<00:01, 5.11MB/s]\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 66.0M/74.7M [00:16<00:01, 4.81MB/s]\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 67.0M/74.7M [00:16<00:01, 4.73MB/s]\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 68.0M/74.7M [00:17<00:01, 4.85MB/s]\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 69.0M/74.7M [00:17<00:01, 4.93MB/s]\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 70.0M/74.7M [00:17<00:01, 4.60MB/s]\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 71.0M/74.7M [00:17<00:00, 4.81MB/s]\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 72.0M/74.7M [00:18<00:00, 4.52MB/s]\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 73.0M/74.7M [00:18<00:00, 4.58MB/s]\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 74.0M/74.7M [00:18<00:00, 4.39MB/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74.7M/74.7M [00:18<00:00, 4.20MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d salikhussaini49/prediction-of-sepsis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8f4296f-6ba9-4cce-a7b5-b74f30513f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset extracted successfully!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "dataset_zip = \"prediction-of-sepsis.zip\"\n",
    "\n",
    "with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"prediction_of_sepsis\")  # Extract to a folder\n",
    "\n",
    "print(\"Dataset extracted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30ff2c14-ce86-4dcf-99ea-b64beed6db01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found. Check the path and filename.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = \"C:\\\\Users\\\\Admin\\\\prediction_of_sepsis\\\\your_file.csv\"\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(\"File exists!\")\n",
    "else:\n",
    "    print(\"File not found. Check the path and filename.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2a0a14b-655b-49d2-a8c5-2a57d353fbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in directory: ['Dataset.csv', 'LICENSE.txt', 'physionet_challenge_2019_ccm_manuscript.pdf', 'SHA256SUMS.txt', 'training_setA', 'training_setB', 'utility_nonsepsis_diagram.svg', 'utility_sepsis_diagram.svg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\Admin\\\\prediction_of_sepsis\"\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(folder_path)\n",
    "print(\"Files in directory:\", files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c8cf928-3e40-481c-be21-32be4b9b4df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Hour</th>\n",
       "      <th>HR</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>EtCO2</th>\n",
       "      <th>...</th>\n",
       "      <th>Fibrinogen</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Unit1</th>\n",
       "      <th>Unit2</th>\n",
       "      <th>HospAdmTime</th>\n",
       "      <th>ICULOS</th>\n",
       "      <th>SepsisLabel</th>\n",
       "      <th>Patient_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.54</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.54</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>78.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.54</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>73.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.54</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>330.0</td>\n",
       "      <td>68.54</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Hour    HR  O2Sat  Temp    SBP   MAP   DBP  Resp  EtCO2  ...  \\\n",
       "0           0     0   NaN    NaN   NaN    NaN   NaN   NaN   NaN    NaN  ...   \n",
       "1           1     1  65.0  100.0   NaN    NaN  72.0   NaN  16.5    NaN  ...   \n",
       "2           2     2  78.0  100.0   NaN    NaN  42.5   NaN   NaN    NaN  ...   \n",
       "3           3     3  73.0  100.0   NaN    NaN   NaN   NaN  17.0    NaN  ...   \n",
       "4           4     4  70.0  100.0   NaN  129.0  74.0  69.0  14.0    NaN  ...   \n",
       "\n",
       "   Fibrinogen  Platelets    Age  Gender  Unit1  Unit2  HospAdmTime  ICULOS  \\\n",
       "0         NaN        NaN  68.54       0    NaN    NaN        -0.02       1   \n",
       "1         NaN        NaN  68.54       0    NaN    NaN        -0.02       2   \n",
       "2         NaN        NaN  68.54       0    NaN    NaN        -0.02       3   \n",
       "3         NaN        NaN  68.54       0    NaN    NaN        -0.02       4   \n",
       "4         NaN      330.0  68.54       0    NaN    NaN        -0.02       5   \n",
       "\n",
       "   SepsisLabel  Patient_ID  \n",
       "0            0       17072  \n",
       "1            0       17072  \n",
       "2            0       17072  \n",
       "3            0       17072  \n",
       "4            0       17072  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Correct file path\n",
    "file_path = \"C:\\\\Users\\\\Admin\\\\prediction_of_sepsis\\\\Dataset.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ae071da-60ce-428e-8892-8ebf387405d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                0\n",
      "Hour                      0\n",
      "HR                   153399\n",
      "O2Sat                202736\n",
      "Temp                1026984\n",
      "SBP                  226265\n",
      "MAP                  193270\n",
      "DBP                  486554\n",
      "Resp                 238335\n",
      "EtCO2               1494574\n",
      "BaseExcess          1468065\n",
      "HCO3                1487182\n",
      "FiO2                1422845\n",
      "pH                  1444637\n",
      "PaCO2               1465909\n",
      "SaO2                1498649\n",
      "AST                 1527027\n",
      "BUN                 1445642\n",
      "Alkalinephos        1527269\n",
      "Calcium             1460879\n",
      "Chloride            1481744\n",
      "Creatinine          1457594\n",
      "Bilirubin_direct    1549220\n",
      "Glucose             1286694\n",
      "Lactate             1510764\n",
      "Magnesium           1454259\n",
      "Phosphate           1489909\n",
      "Potassium           1407685\n",
      "Bilirubin_total     1529069\n",
      "TroponinI           1537429\n",
      "Hct                 1414777\n",
      "Hgb                 1437619\n",
      "PTT                 1506511\n",
      "WBC                 1452763\n",
      "Fibrinogen          1541968\n",
      "Platelets           1460001\n",
      "Age                       0\n",
      "Gender                    0\n",
      "Unit1                611960\n",
      "Unit2                611960\n",
      "HospAdmTime               8\n",
      "ICULOS                    0\n",
      "SepsisLabel               0\n",
      "Patient_ID                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check missing values in dataset\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d2e1ebc-4a0d-4b7d-9ee6-c3dd31df1d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e019638e-1391-48fe-b048-7c50bf169fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0          0\n",
      "Hour                0\n",
      "HR                  0\n",
      "O2Sat               0\n",
      "Temp                0\n",
      "SBP                 0\n",
      "MAP                 0\n",
      "DBP                 0\n",
      "Resp                0\n",
      "EtCO2               0\n",
      "BaseExcess          0\n",
      "HCO3                0\n",
      "FiO2                0\n",
      "pH                  0\n",
      "PaCO2               0\n",
      "SaO2                0\n",
      "AST                 0\n",
      "BUN                 0\n",
      "Alkalinephos        0\n",
      "Calcium             0\n",
      "Chloride            0\n",
      "Creatinine          0\n",
      "Bilirubin_direct    0\n",
      "Glucose             0\n",
      "Lactate             0\n",
      "Magnesium           0\n",
      "Phosphate           0\n",
      "Potassium           0\n",
      "Bilirubin_total     0\n",
      "TroponinI           0\n",
      "Hct                 0\n",
      "Hgb                 0\n",
      "PTT                 0\n",
      "WBC                 0\n",
      "Fibrinogen          0\n",
      "Platelets           0\n",
      "Age                 0\n",
      "Gender              0\n",
      "Unit1               0\n",
      "Unit2               0\n",
      "HospAdmTime         0\n",
      "ICULOS              0\n",
      "SepsisLabel         0\n",
      "Patient_ID          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check missing values in dataset\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b18ee733-a019-483d-97e1-bd10b70c5612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropna: (0, 44)\n",
      "After dropna: (0, 44)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before dropna:\", df.shape)\n",
    "df = df.dropna()\n",
    "print(\"After dropna:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aeae1719-a802-43e2-9575-c2cd23cb1bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, Hour, HR, O2Sat, Temp, SBP, MAP, DBP, Resp, EtCO2, BaseExcess, HCO3, FiO2, pH, PaCO2, SaO2, AST, BUN, Alkalinephos, Calcium, Chloride, Creatinine, Bilirubin_direct, Glucose, Lactate, Magnesium, Phosphate, Potassium, Bilirubin_total, TroponinI, Hct, Hgb, PTT, WBC, Fibrinogen, Platelets, Age, Gender, Unit1, Unit2, HospAdmTime, ICULOS, SepsisLabel, Patient_ID]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2d12ec0c-d2b1-4aca-adad-8bd1f659c68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1552210, 44)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\Admin\\\\prediction_of_sepsis\\\\Dataset.csv\")\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "560c5fd7-7b82-4b57-92ea-b62ea0bf480a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                0\n",
      "Hour                      0\n",
      "HR                   153399\n",
      "O2Sat                202736\n",
      "Temp                1026984\n",
      "SBP                  226265\n",
      "MAP                  193270\n",
      "DBP                  486554\n",
      "Resp                 238335\n",
      "EtCO2               1494574\n",
      "BaseExcess          1468065\n",
      "HCO3                1487182\n",
      "FiO2                1422845\n",
      "pH                  1444637\n",
      "PaCO2               1465909\n",
      "SaO2                1498649\n",
      "AST                 1527027\n",
      "BUN                 1445642\n",
      "Alkalinephos        1527269\n",
      "Calcium             1460879\n",
      "Chloride            1481744\n",
      "Creatinine          1457594\n",
      "Bilirubin_direct    1549220\n",
      "Glucose             1286694\n",
      "Lactate             1510764\n",
      "Magnesium           1454259\n",
      "Phosphate           1489909\n",
      "Potassium           1407685\n",
      "Bilirubin_total     1529069\n",
      "TroponinI           1537429\n",
      "Hct                 1414777\n",
      "Hgb                 1437619\n",
      "PTT                 1506511\n",
      "WBC                 1452763\n",
      "Fibrinogen          1541968\n",
      "Platelets           1460001\n",
      "Age                       0\n",
      "Gender                    0\n",
      "Unit1                611960\n",
      "Unit2                611960\n",
      "HospAdmTime               8\n",
      "ICULOS                    0\n",
      "SepsisLabel               0\n",
      "Patient_ID                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "42e2b3e9-506e-4759-b1d9-9a82f6f74110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0          0\n",
      "Hour                0\n",
      "HR             153399\n",
      "O2Sat          202736\n",
      "SBP            226265\n",
      "MAP            193270\n",
      "DBP            486554\n",
      "Resp           238335\n",
      "Age                 0\n",
      "Gender              0\n",
      "Unit1          611960\n",
      "Unit2          611960\n",
      "HospAdmTime         8\n",
      "ICULOS              0\n",
      "SepsisLabel         0\n",
      "Patient_ID          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with more than 50% missing data\n",
    "df_cleaned = df.dropna(thresh=df.shape[0]*0.5, axis=1)\n",
    "print(df_cleaned.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d3e0a516-5132-49e5-9e6d-b15a5e816884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with the mode (most frequent value) without using inplace\n",
    "df['Gender'] = df['Gender'].fillna(df['Gender'].mode()[0])\n",
    "df['Unit1'] = df['Unit1'].fillna(df['Unit1'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb7bc3f1-6874-4b67-8351-f3171e6c71fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with the mean for numerical columns\n",
    "df['HR'] = df['HR'].fillna(df['HR'].mean())\n",
    "df['O2Sat'] = df['O2Sat'].fillna(df['O2Sat'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8dc62b51-ec7a-4031-8231-e1911fa3c910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with 0 for 'HospAdmTime'\n",
    "df['HospAdmTime'] = df['HospAdmTime'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bb8b48de-d858-428a-a6f8-5614eac6dd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                0\n",
      "Hour                      0\n",
      "HR                        0\n",
      "O2Sat                     0\n",
      "Temp                1026984\n",
      "SBP                  226265\n",
      "MAP                  193270\n",
      "DBP                  486554\n",
      "Resp                 238335\n",
      "EtCO2               1494574\n",
      "BaseExcess          1468065\n",
      "HCO3                1487182\n",
      "FiO2                1422845\n",
      "pH                  1444637\n",
      "PaCO2               1465909\n",
      "SaO2                1498649\n",
      "AST                 1527027\n",
      "BUN                 1445642\n",
      "Alkalinephos        1527269\n",
      "Calcium             1460879\n",
      "Chloride            1481744\n",
      "Creatinine          1457594\n",
      "Bilirubin_direct    1549220\n",
      "Glucose             1286694\n",
      "Lactate             1510764\n",
      "Magnesium           1454259\n",
      "Phosphate           1489909\n",
      "Potassium           1407685\n",
      "Bilirubin_total     1529069\n",
      "TroponinI           1537429\n",
      "Hct                 1414777\n",
      "Hgb                 1437619\n",
      "PTT                 1506511\n",
      "WBC                 1452763\n",
      "Fibrinogen          1541968\n",
      "Platelets           1460001\n",
      "Age                       0\n",
      "Gender                    0\n",
      "Unit1                     0\n",
      "Unit2                611960\n",
      "HospAdmTime               0\n",
      "ICULOS                    0\n",
      "SepsisLabel               0\n",
      "Patient_ID                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())  # Check if there are any remaining NaN values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3868388d-474b-4aa5-bec0-e6647328c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in numerical columns with the median (safer for outliers)\n",
    "numerical_columns = ['Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2', 'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2',\n",
    "                     'AST', 'BUN', 'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct', 'Glucose', 'Lactate',\n",
    "                     'Magnesium', 'Phosphate', 'Potassium', 'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC',\n",
    "                     'Fibrinogen', 'Platelets']\n",
    "\n",
    "# Filling missing values in numerical columns with median\n",
    "for col in numerical_columns:\n",
    "    df[col] = df[col].fillna(df[col].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2a69b689-9e4b-4387-9744-ea3d19533a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in categorical columns with the mode\n",
    "categorical_columns = ['Gender', 'Unit1', 'Unit2']\n",
    "\n",
    "# Filling missing values in categorical columns with mode\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9c896120-0067-4263-a8af-2fbca37da721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with 0 for 'HospAdmTime'\n",
    "df['HospAdmTime'] = df['HospAdmTime'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "89db8ad1-b91d-4c15-9579-89e574d00b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0          0\n",
      "Hour                0\n",
      "HR                  0\n",
      "O2Sat               0\n",
      "Temp                0\n",
      "SBP                 0\n",
      "MAP                 0\n",
      "DBP                 0\n",
      "Resp                0\n",
      "EtCO2               0\n",
      "BaseExcess          0\n",
      "HCO3                0\n",
      "FiO2                0\n",
      "pH                  0\n",
      "PaCO2               0\n",
      "SaO2                0\n",
      "AST                 0\n",
      "BUN                 0\n",
      "Alkalinephos        0\n",
      "Calcium             0\n",
      "Chloride            0\n",
      "Creatinine          0\n",
      "Bilirubin_direct    0\n",
      "Glucose             0\n",
      "Lactate             0\n",
      "Magnesium           0\n",
      "Phosphate           0\n",
      "Potassium           0\n",
      "Bilirubin_total     0\n",
      "TroponinI           0\n",
      "Hct                 0\n",
      "Hgb                 0\n",
      "PTT                 0\n",
      "WBC                 0\n",
      "Fibrinogen          0\n",
      "Platelets           0\n",
      "Age                 0\n",
      "Gender              0\n",
      "Unit1               0\n",
      "Unit2               0\n",
      "HospAdmTime         0\n",
      "ICULOS              0\n",
      "SepsisLabel         0\n",
      "Patient_ID          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any missing values left\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ccdf0d0f-36df-4792-bbd9-572f3df69ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming df is your DataFrame, and the target column is 'SepsisLabel'\n",
    "X = df.drop(columns=['SepsisLabel'])\n",
    "y = df['SepsisLabel']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an imputer to fill missing values with the mean\n",
    "imputer = SimpleImputer(strategy='mean')  # You can use 'median' or 'most_frequent' as well\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Standardize the data (optional, but often helpful for gradient boosting)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Create and train the GradientBoostingClassifier\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "gb_predictions = gb_model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "372abd0a-b792-4f9f-8656-bdc42d0b3706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest Model...\n",
      "\n",
      "Random Forest Accuracy: 0.9837425348374254\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    304903\n",
      "           1       0.93      0.10      0.17      5539\n",
      "\n",
      "    accuracy                           0.98    310442\n",
      "   macro avg       0.96      0.55      0.58    310442\n",
      "weighted avg       0.98      0.98      0.98    310442\n",
      "\n",
      "\n",
      "Training Gradient Boosting Model...\n",
      "\n",
      "Gradient Boosting Accuracy: 0.9822156795794383\n",
      "Gradient Boosting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    304903\n",
      "           1       0.60      0.01      0.02      5539\n",
      "\n",
      "    accuracy                           0.98    310442\n",
      "   macro avg       0.79      0.50      0.50    310442\n",
      "weighted avg       0.98      0.98      0.97    310442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load your dataset\n",
    "# Replace 'path_to_your_dataset.csv' with the actual file path\n",
    "df = pd.read_csv('C:\\\\Users\\\\Admin\\\\prediction_of_sepsis\\\\Dataset.csv')\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X = df.drop('SepsisLabel', axis=1)  # Features (exclude target column)\n",
    "y = df['SepsisLabel']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 1. Impute missing values using SimpleImputer (mean for numeric columns)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# 2. Scaling the features (important for some models like Gradient Boosting)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# 1. Random Forest Classifier\n",
    "print(\"Training Random Forest Model...\")\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_predictions = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nRandom Forest Accuracy:\", accuracy_score(y_test, rf_predictions))\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, rf_predictions))\n",
    "\n",
    "# 2. Gradient Boosting Classifier\n",
    "print(\"\\nTraining Gradient Boosting Model...\")\n",
    "# Initialize the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "gb_predictions = gb_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nGradient Boosting Accuracy:\", accuracy_score(y_test, gb_predictions))\n",
    "print(\"Gradient Boosting Classification Report:\\n\", classification_report(y_test, gb_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7117da-5f2e-4adb-9517-1cfb291bf3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
