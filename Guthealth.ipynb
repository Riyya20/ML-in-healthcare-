{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyONR8iupjlg4BZN1ilFuGhu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":672},"id":"ovh8stxxzxOx","executionInfo":{"status":"error","timestamp":1732213893441,"user_tz":-330,"elapsed":19785,"user":{"displayName":"Aditya Kumar Userethe","userId":"06224134489430541104"}},"outputId":"70b51763-1724-4a8e-c546-243f75d39915"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-9402851d-2772-4c75-a722-334300459144\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-9402851d-2772-4c75-a722-334300459144\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving microbiome to obesity and T2D combine.xlsx to microbiome to obesity and T2D combine (17).xlsx\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\n","Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","count    707.0\n","mean       1.0\n","std        0.0\n","min        1.0\n","25%        1.0\n","50%        1.0\n","75%        1.0\n","max        1.0\n","dtype: float64\n"]},{"output_type":"error","ename":"TypeError","evalue":"at least two inputs are required; got 1.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-ac969ce3c56a>\u001b[0m in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbmi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmicrobiome_bins\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmicrobiome_bins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0manova_f_stat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manova_p_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_oneway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/stats/_axis_nan_policy.py\u001b[0m in \u001b[0;36maxis_nan_policy_wrapper\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msentinel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_remove_sentinel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaired\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentinel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhypotest_fun_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_add_reduced_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduced_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36mf_oneway\u001b[0;34m(axis, *samples)\u001b[0m\n\u001b[1;32m   4086\u001b[0m     \"\"\"\n\u001b[1;32m   4087\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4088\u001b[0;31m         raise TypeError('at least two inputs are required;'\n\u001b[0m\u001b[1;32m   4089\u001b[0m                         f' got {len(samples)}.')\n\u001b[1;32m   4090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: at least two inputs are required; got 1."]}],"source":["from google.colab import files\n","uploaded = files.upload()\n","\n","!pip install --upgrade pandas\n","\n","import pandas as pd\n","import numpy as np\n","from scipy.stats import pearsonr, spearmanr, kendalltau, ttest_ind, f_oneway, mannwhitneyu, kruskal\n","from sklearn.linear_model import LinearRegression\n","\n","\n","file_name = \"microbiome to obesity and T2D combine.xlsx\"\n","data = pd.read_excel(\"microbiome to obesity and T2D combine.xlsx\")\n","\n","if data.isnull().sum().any():\n","    data = data.dropna()\n","\n","\n","microbiome = data['Organism Name']\n","bmi = data['BMI, kg/m2']\n","hba1c = data['HbA1c, mmol/mol']\n","\n","microbiome_dummies = pd.get_dummies(data['Organism Name'], prefix='Organism')\n","data = pd.concat([data, microbiome_dummies], axis=1)\n","bmi = data['BMI, kg/m2']\n","hba1c = data['HbA1c, mmol/mol']\n","\n","\n","for organism in microbiome_dummies.columns:\n","    pearson_corr_bmi, p_value_bmi = pearsonr(data[organism], bmi)\n","    pearson_corr_hba1c, p_value_hba1c = pearsonr(data[organism], hba1c)\n","\n","\n","microbiome_median = data[microbiome_dummies.columns].sum(axis=1).median()\n","group1 = bmi[data[microbiome_dummies.columns].sum(axis=1) <= microbiome_median]\n","group2 = bmi[data[microbiome_dummies.columns].sum(axis=1) > microbiome_median]\n","t_stat, t_p_value = ttest_ind(group1, group2)\n","\n","\n","microbiome_total = data[microbiome_dummies.columns].sum(axis=1)\n","print(microbiome_total.describe())\n","\n","microbiome_total_no_dupes = microbiome_total.drop_duplicates()\n","microbiome_bins = pd.qcut(\n","    microbiome_total,\n","    q=3,\n","    labels=False,\n","    duplicates='drop'\n",")\n","\n","bin_mapping = dict(zip(microbiome_total_no_dupes, microbiome_bins))\n","microbiome_bins = microbiome_total.map(bin_mapping)\n","\n","unique_bins = microbiome_bins.unique()\n","num_bins = len(unique_bins)\n","labels = [\"Low\", \"Medium\", \"High\"][:num_bins]\n","microbiome_bins = microbiome_bins.map(dict(zip(unique_bins, labels)))\n","\n","groups = [bmi[microbiome_bins == group] for group in microbiome_bins.unique()]\n","anova_f_stat, anova_p_value = f_oneway(*groups)\n","\n","\n","X = data[microbiome_dummies.columns]\n","y = bmi.values\n","reg = LinearRegression().fit(X, y)\n","regression_coef = reg.coef_\n","\n","\n","\n","spearman_corr_bmi, spearman_p_bmi = spearmanr(data[microbiome_dummies.columns].sum(axis=1), bmi)\n","spearman_corr_hba1c, spearman_p_hba1c = spearmanr(data[microbiome_dummies.columns].sum(axis=1), hba1c)\n","\n","\n","u_stat, u_p_value = mannwhitneyu(group1, group2)\n","\n","\n","kruskal_stat, kruskal_p_value = kruskal(*groups)\n","\n","\n","kendall_corr_bmi, kendall_p_bmi = kendalltau(data[microbiome_dummies.columns].sum(axis=1), bmi)\n","kendall_corr_hba1c, kendall_p_hba1c = kendalltau(data[microbiome_dummies.columns].sum(axis=1), hba1c)\n","\n","\n","print(\"Parametric Tests:\")\n","print(f\"1. Pearson Correlation (BMI): {pearson_corr_bmi}, p-value: {p_value_bmi}\")\n","print(f\"   Pearson Correlation (HbA1c): {pearson_corr_hba1c}, p-value: {p_value_hba1c}\")\n","print(f\"2. T-test: t-statistic: {t_stat}, p-value: {t_p_value}\")\n","print(f\"3. ANOVA: F-statistic: {anova_f_stat}, p-value: {anova_p_value}\")\n","print(f\"4. Linear Regression Coefficient (Microbiome vs BMI): {regression_coef}\")\n","\n","print(\"\\nNon-Parametric Tests:\")\n","print(f\"1. Spearman Correlation (BMI): {spearman_corr_bmi}, p-value: {spearman_p_bmi}\")\n","print(f\"   Spearman Correlation (HbA1c): {spearman_corr_hba1c}, p-value: {spearman_p_hba1c}\")\n","print(f\"2. Mann-Whitney U: U-statistic: {u_stat}, p-value: {u_p_value}\")\n","print(f\"3. Kruskal-Wallis: H-statistic: {kruskal_stat}, p-value: {kruskal_p_value}\")\n","print(f\"4. Kendall Tau (BMI): {kendall_corr_bmi}, p-value: {kendall_p_bmi}\")\n","print(f\"   Kendall Tau (HbA1c): {kendall_corr_hba1c}, p-value: {kendall_p_hba1c}\")\n"]},{"source":["from google.colab import files\n","uploaded = files.upload()\n","\n","\n","import pandas as pd\n","import numpy as np\n","from scipy.stats import pearsonr, spearmanr, kendalltau, ttest_ind, f_oneway, mannwhitneyu, kruskal\n","from sklearn.linear_model import LinearRegression\n","\n","\n","file_name = \"microbiome to obesity and T2D combine.xlsx\"\n","data = pd.read_excel(\"microbiome to obesity and T2D combine.xlsx\")\n","\n","if data.isnull().sum().any():\n","    data = data.dropna()\n","\n","\n","microbiome = data['Organism Name']\n","bmi = data['BMI, kg/m2']\n","hba1c = data['HbA1c, mmol/mol']\n","\n","microbiome_dummies = pd.get_dummies(data['Organism Name'], prefix='Organism')\n","data = pd.concat([data, microbiome_dummies], axis=1)\n","bmi = data['BMI, kg/m2']\n","hba1c = data['HbA1c, mmol/mol']\n","\n","\n","for organism in microbiome_dummies.columns:\n","    pearson_corr_bmi, p_value_bmi = pearsonr(data[organism], bmi)\n","    pearson_corr_hba1c, p_value_hba1c = pearsonr(data[organism], hba1c)\n","\n","\n","microbiome_median = data[microbiome_dummies.columns].sum(axis=1).median()\n","group1 = bmi[data[microbiome_dummies.columns].sum(axis=1) <= microbiome_median]\n","group2 = bmi[data[microbiome_dummies.columns].sum(axis=1) > microbiome_median]\n","\n","if group1.empty or group2.empty:\n","    print(\"Warning: One or both groups are empty. Adjusting microbiome_median...\")\n","\n","    adjustment_factor = 0.99\n","\n","    while group1.empty or group2.empty:\n","        microbiome_median *= 0.99\n","        group1 = bmi[data[microbiome_dummies.columns].sum(axis=1) <= microbiome_median]\n","        group2 = bmi[data[microbiome_dummies.columns].sum(axis=1) > microbiome_median]\n","\n","    if microbiome_median < 0.1:\n","        print(\"Warning: Could not create non-empty groups. Skipping Mann-Whitney U test.\")\n","        u_stat, u_p_value = np.nan, np.nan\n","    else:\n","        u_stat, u_p_value = mannwhitneyu(group1, group2)\n","\n","\n","\n","if not group1.empty and not group2.empty:\n","     u_stat, u_p_value = mannwhitneyu(group1, group2)\n","else:\n","    u_stat, u_p_value = np.nan, np.nan\n","\n","\n","microbiome_total = data[microbiome_dummies.columns].sum(axis=1)\n","print(microbiome_total.describe())\n","\n","\n","if microbiome_total.nunique() < 3:\n","\n","    microbiome_bins = pd.qcut(microbiome_total, q=3, labels=False, duplicates='drop')\n","else:\n","\n","    microbiome_total_no_dupes = microbiome_total.drop_duplicates()\n","    microbiome_bins = pd.qcut(\n","        microbiome_total,\n","        q=3,\n","        labels=False,\n","        duplicates='drop'\n","    )\n","    bin_mapping = dict(zip(microbiome_total_no_dupes, microbiome_bins))\n","    microbiome_bins = microbiome_total.map(bin_mapping)\n","\n","unique_bins = microbiome_bins.unique()\n","num_bins = len(unique_bins)\n","labels = [\"Low\", \"Medium\", \"High\"][:num_bins]\n","microbiome_bins = microbiome_bins.map(dict(zip(unique_bins, labels)))\n","\n","groups = [bmi[microbiome_bins == group] for group in microbiome_bins.unique()]\n","\n","X = data[microbiome_dummies.columns]\n","y = bmi.values\n","reg = LinearRegression().fit(X, y)\n","regression_coef = reg.coef_\n","\n","\n","\n","spearman_corr_bmi, spearman_p_bmi = spearmanr(data[microbiome_dummies.columns].sum(axis=1), bmi)\n","spearman_corr_hba1c, spearman_p_hba1c = spearmanr(data[microbiome_dummies.columns].sum(axis=1), hba1c)\n","\n","\n","u_stat, u_p_value = mannwhitneyu(group1, group2)\n","\n","\n","kruskal_stat, kruskal_p_value = kruskal(*groups)\n","\n","\n","kendall_corr_bmi, kendall_p_bmi = kendalltau(data[microbiome_dummies.columns].sum(axis=1), bmi)\n","kendall_corr_hba1c, kendall_p_hba1c = kendalltau(data[microbiome_dummies.columns].sum(axis=1), hba1c)\n","\n","\n","print(\"Parametric Tests:\")\n","print(f\"1. Pearson Correlation (BMI): {pearson_corr_bmi}, p-value: {p_value_bmi}\")\n","print(f\"   Pearson Correlation (HbA1c): {pearson_corr_hba1c}, p-value: {p_value_hba1c}\")\n","print(f\"2. T-test: t-statistic: {t_stat}, p-value: {t_p_value}\")\n","print(f\"3. ANOVA: F-statistic: {anova_f_stat}, p-value: {anova_p_value}\")\n","print(f\"4. Linear Regression Coefficient (Microbiome vs BMI): {regression_coef}\")\n","\n","print(\"\\nNon-Parametric Tests:\")\n","print(f\"1. Spearman Correlation (BMI): {spearman_corr_bmi}, p-value: {spearman_p_bmi}\")\n","print(f\"   Spearman Correlation (HbA1c): {spearman_corr_hba1c}, p-value: {spearman_p_hba1c}\")\n","print(f\"2. Mann-Whitney U: U-statistic: {u_stat}, p-value: {u_p_value}\")\n","print(f\"3. Kruskal-Wallis: H-statistic: {kruskal_stat}, p-value: {kruskal_p_value}\")\n","print(f\"4. Kendall Tau (BMI): {kendall_corr_bmi}, p-value: {kendall_p_bmi}\")\n","print(f\"   Kendall Tau (HbA1c): {kendall_corr_hba1c}, p-value: {kendall_p_hba1c}\")\n"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"WoR85TqD_zA8","outputId":"9245c88d-1f5e-4830-ac04-edd516605b78"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-5c89f9da-2eed-405a-9a90-295858049ac1\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-5c89f9da-2eed-405a-9a90-295858049ac1\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving microbiome to obesity and T2D combine.xlsx to microbiome to obesity and T2D combine (26).xlsx\n","Warning: One or both groups are empty. Adjusting microbiome_median...\n"]}]}]}